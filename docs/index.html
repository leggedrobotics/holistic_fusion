<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Holistic Fusion: Task and Setup-agnostic Robot Localization and State Estimation with Factor Graphs</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 40px;
            text-align: center;
            background-color: #f9f9f9;
        }
        .container {
            max-width: 800px;
            margin: auto;
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        .title {
            font-size: 24px;
            font-weight: bold;
        }
        .authors {
            font-size: 18px;
            color: #555;
            margin-top: 5px;
        }
        .abstract {
            text-align: justify;
            margin-top: 20px;
            font-size: 16px;
        }
        .btn {
            display: inline-block;
            margin-top: 20px;
            padding: 10px 20px;
            font-size: 16px;
            color: white;
            background-color: #007bff;
            text-decoration: none;
            border-radius: 5px;
            transition: background 0.3s;
        }
        .btn:hover {
            background-color: #0056b3;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="title">Holistic Fusion: Task and Setup-agnostic Robot Localization and State Estimation with Factor Graphs</div>
        <div class="authors">Julian Nubert, Turcan Tuna, Jonas Frey, Cesar Cadena, Katherine J. Kuchenbecker, Shehryar Khattak, Marco Hutter</div>
        <hr>
        <div class="abstract">
            <strong>Abstract:</strong> 
		Modern robotic systems must be able to operate in challenging environments seamlessly and often require low-latency local motion estimation (e.g., for dynamic maneuvers) and accurate \textit{global} localization (e.g., for wayfinding).
		While most existing sensor fusion solutions are designed with specific tasks or setups in mind, this work introduces a flexible solution for task- and setup-agnostic multi-modal sensor fusion called Holistic Fusion that distinguishes in its generality and simple adaptability to new tasks.
		HF formulates sensor fusion as a holistic (combined) estimation problem of i) the local and global robot state and ii) the relationship of a (theoretically unlimited) number of dynamic context variables, e.g., for the automatic alignment of coordinate reference frames, which fits a large body of real-world applications without any conceptual modifications.
		In particular, the proposed factor graph solution enables the direct fusion of a (theoretically) arbitrary number of absolute-, local-, and landmark measurements expressed w.r.t. different reference frames.
		To account for the drift of different absolute measurements, the evolution of the reference frames is modeled as a random walk. 
		Moreover, to handle jumps in the robot state belief, particular attention is given to both local smoothness and consistency while ensuring global accuracy.
		The proposed solution enables low-latency and smooth state estimation on typical robot hardware and provides low-drift globally consistent estimates in robot states at IMU-rate. %post-mission offline optimization, 
		The efficacy of the released proposed framework is demonstrated in six distinct real-world scenarios on three robotic platforms, each with different task requirements.
        </div>
        <a href="https://github.com/leggedrobotics/holistic_fusion" class="btn">Github</a>
        <a href="https://youtube.com/leggedrobotics" class="btn">Video</a>
        <a href="docs/index.html" class="btn">Read The Docs</a>
        <a href="doxy/index.html" class="btn">Doxygen</a>
    </div>
</body>
</html>

